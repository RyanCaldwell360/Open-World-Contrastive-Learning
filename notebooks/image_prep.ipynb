{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6929a096",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "- [ ] Download CIFAR100 data from TF/Keras\n",
    "- [ ] Write data to disk\n",
    "- [ ] Normalize Images\n",
    "- [ ] Randomly split images into train/val/test sets\n",
    "- [ ] Write normalized train/val/test images to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c4a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b919294",
   "metadata": {},
   "source": [
    "# Download CIFAR100 Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0b3bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(X_train, y_train_coarse), (X_test, y_test_coarse) = tf.keras.datasets.cifar100.load_data(label_mode='coarse')\n",
    "(_, y_train_fine), (_, y_test_fine) = tf.keras.datasets.cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5ce6b5",
   "metadata": {},
   "source": [
    "# Create Directories for Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c49996",
   "metadata": {},
   "source": [
    "Can use a yaml config file to set these paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7cfd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = '../data'\n",
    "download_path = parent_path + '/downloads'\n",
    "train_val_test_path = parent_path +'/train_val_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474d549",
   "metadata": {},
   "source": [
    "Create the specified paths if they don't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3449280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory ../data already exists\n",
      "Download path ../data/downloads already exists\n",
      "Train/Val/Test split path ../data/train_val_test already exists\n"
     ]
    }
   ],
   "source": [
    "# check if the parent directory exists\n",
    "if os.path.exists(parent_path):\n",
    "    print(\"Parent directory {} already exists\".format(parent_path))\n",
    "    # check if sub directories exist\n",
    "    if os.path.exists(download_path):\n",
    "        print(\"Download path {} already exists\".format(download_path))\n",
    "    else:\n",
    "        os.makedirs(download_path)\n",
    "        \n",
    "    if os.path.exists(train_val_test_path):\n",
    "        print(\"Train/Val/Test split path {} already exists\".format(train_val_test_path))\n",
    "else:\n",
    "    print(\"Parent directory doesn't exist\")\n",
    "    os.makedirs(parent_path)\n",
    "    os.makedirs(download_path)\n",
    "    os.makedirs(train_val_test_path)\n",
    "    print(\"Created directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20a281",
   "metadata": {},
   "source": [
    "# Write Downloaded Data to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e88f0c",
   "metadata": {},
   "source": [
    "Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9944d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(download_path+'/train.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "    \n",
    "with open(download_path+'/test.npy', 'wb') as f:\n",
    "    np.save(f, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92206742",
   "metadata": {},
   "source": [
    "superclasses and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58395441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# superclasses\n",
    "with open(download_path+'/train_superclasses.npy', 'wb') as f:\n",
    "    np.save(f, y_train_coarse)\n",
    "    \n",
    "with open(download_path+'/test_superclasses.npy', 'wb') as f:\n",
    "    np.save(f, y_test_coarse)\n",
    "    \n",
    "# classes\n",
    "with open(download_path+'/train_classes.npy', 'wb') as f:\n",
    "    np.save(f, y_train_fine)\n",
    "    \n",
    "with open(download_path+'/test_classes.npy', 'wb') as f:\n",
    "    np.save(f, y_test_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8560ca0",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2878099",
   "metadata": {},
   "source": [
    "Images are represented with 3 color channels with pixel values between 0 and 255, inclusive. We can normalize these pixel values to range between 0 and 1 by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7df9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 3) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "images = np.vstack((X_train, X_test))/255.\n",
    "print(images.shape, np.min(images), np.max(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60e99d",
   "metadata": {},
   "source": [
    "# Combine Downloaded Train/Test Labels into DataFrame\n",
    "We will use this dataframe to create our open-world setup:\n",
    "1. Train: known superclasses\n",
    "1. Val: same known superclasses as in the Train data\n",
    "1. Test:\n",
    "    1. known superclasses seen in the Train/Val but unlabeled\n",
    "    1. novel superclasses not seen in the Train/Val images\n",
    "    \n",
    "Think of this open-world problem in the following way. At some point in time you are training an image classification model. You have a database of labelled images. At a future point in time you accumulate new images that are unlabeled and you still want to generate predictions, but are aware that these images could either belong to the labels found in the training data, or might be novel and new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c7c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_coarse = [x[0] for x in y_train_coarse]\n",
    "y_test_coarse = [x[0] for x in y_test_coarse]\n",
    "\n",
    "y_train_fine = [x[0] for x in y_train_fine]\n",
    "y_test_fine = [x[0] for x in y_test_fine]\n",
    "\n",
    "train_labels = pd.DataFrame({'coarse':y_train_coarse,\n",
    "                             'fine':y_train_fine})\n",
    "\n",
    "test_labels = pd.DataFrame({'coarse':y_test_coarse,\n",
    "                            'fine':y_test_fine})\n",
    "\n",
    "labels = pd.concat([train_labels, test_labels])\\\n",
    "           .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3beee85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 100\n"
     ]
    }
   ],
   "source": [
    "n_superclasses = len(set(labels.coarse))\n",
    "n_classes = len(set(labels.fine))\n",
    "print(n_superclasses, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2d486",
   "metadata": {},
   "source": [
    "# Split Data Into Train/Val/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9f237",
   "metadata": {},
   "source": [
    "A configurable parameter could be the number of superclasses to include in our train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a30296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 4\n"
     ]
    }
   ],
   "source": [
    "n_train_val_superclasses = int(0.8*(n_superclasses))\n",
    "n_novel_superclasses = n_superclasses - n_train_val_superclasses\n",
    "print(n_train_val_superclasses, n_novel_superclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6150ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "superclasses = list(set(labels.coarse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a8959bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 5, 11, 9, 15, 12, 8, 16, 10, 19, 2, 6, 0, 7, 17, 14]\n",
      "[1, 3, 4, 18]\n"
     ]
    }
   ],
   "source": [
    "train_val_superclasses = [x for x in np.random.choice(superclasses, n_train_val_superclasses, replace=False)]\n",
    "novel_superclasses = [x for x in superclasses if x not in train_val_superclasses]\n",
    "print(train_val_superclasses)\n",
    "print(novel_superclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c677a4",
   "metadata": {},
   "source": [
    "Get indexes of our train/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c31958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n"
     ]
    }
   ],
   "source": [
    "train_val_indexes = [x for x in labels[labels['coarse'].isin(train_val_superclasses)].index]\n",
    "novel_indexes = [x for x in labels[labels['coarse'].isin(novel_superclasses)].index]\n",
    "print(len(train_val_indexes), len(novel_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789df41d",
   "metadata": {},
   "source": [
    "We need to take some of the train_val_indexes and split into our test data so we have the population of images that belong to the known classes, but are unlabelled. This can also be a configurable parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f05d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unlabeled_perc = 0.20\n",
    "val_perc = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "246fa9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_indexes, test_unlabeled_indexes = train_test_split(train_val_indexes, test_size=test_unlabeled_perc)\n",
    "train_indexes, val_indexes = train_test_split(train_val_indexes, test_size=val_perc)\n",
    "test_indexes = test_unlabeled_indexes + novel_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b0fccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 30720 7680 21600\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape[0], len(train_indexes), len(val_indexes), len(test_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805f8f0",
   "metadata": {},
   "source": [
    "Subset images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23588d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[train_indexes, :, :, :]\n",
    "train_labels = labels.iloc[train_indexes, :].values\n",
    "\n",
    "X_val = images[val_indexes, :, :, :]\n",
    "val_labels = labels.iloc[val_indexes, :].values\n",
    "\n",
    "X_test = images[test_indexes, :, :, :]\n",
    "test_labels = labels.iloc[test_indexes, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e77ba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((30720, 32, 32, 3), (30720, 2)) ((7680, 32, 32, 3), (7680, 2)) ((21600, 32, 32, 3), (21600, 2))\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape, train_labels.shape), (X_val.shape, val_labels.shape), (X_test.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37593be",
   "metadata": {},
   "source": [
    "# Write Data to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2be0e4",
   "metadata": {},
   "source": [
    "Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bc7453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_val_test_path+'/train.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "    \n",
    "with open(train_val_test_path+'/val.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "    \n",
    "with open(train_val_test_path+'/test.npy', 'wb') as f:\n",
    "    np.save(f, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdc369",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "324479a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_val_test_path+'/train_labels.npy', 'wb') as f:\n",
    "    np.save(f, train_labels)\n",
    "    \n",
    "with open(train_val_test_path+'/val_labels.npy', 'wb') as f:\n",
    "    np.save(f, val_labels)\n",
    "    \n",
    "with open(train_val_test_path+'/test_labels.npy', 'wb') as f:\n",
    "    np.save(f, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4ddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
